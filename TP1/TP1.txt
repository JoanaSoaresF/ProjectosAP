Attention:
- Do not edit this file in text editors like Word. Use a plain text editor only. If in doubt you can use Spyder as a text editor.
- Do not change the structure of this file. Just fill in your answers in the places provided (After the R#: tag).
- You can add lines in the spaces for your answers but your answers should be brief and straight to the point.

Atenção:
- Não edite este ficheiro em programas como Word e afins. Use exclusivamente um editor de texto simples. Em caso de dúvida, use o editor do Spyder.
- Não altere a estrutura deste ficheiro. Preencha as respostas apenas nos espaços respectivos (a seguir à tag R#:)
- Pode adicionar linhas no espaço para as respostas mas as respostas devem ser sucintas e directas.

Linking images and reports/Incluir imagens e relatórios
- You can link a .png or .html file in your answers by typing the name of the file in a separate line. The file must be in the same folder as this TP1.txt file. See the examples below:
- Pode ligar às respostas um ficheiro .png ou .html escrevendo o nome do ficheiro numa linha separada. O ficheiro tem de estar presente na mesma pasta em que está este ficheiro TP1.txt. Por exemplo:

exemplo.png
exemplo.html

PERGUNTAS/QUESTIONS:

Q1: Explain the architecture of your best model for the multiclass classification problem, including a description and justification of the output activation and loss functions. Also justify your choice of layers and activation functions for the hidden layers.
Q1; Explique a arquitectura do seu melhor modelo para o problema de classificação de multi-classe, incluindo uma descrição e justificação das funções de activação à saída da rede e função de custo. Justifique também a sua escolha de camadas e de funções de activação para as camadas escondidas.
R1:
Convolutional neural networks são largamente usadas para reconhecimento e classificação de imagens, permitindo alcançar excelentes resultados nestes objetivos. Por esse motivo escolhemos implementar uma CNN para o problema da multiclass classification. Os aspetos chaves que levam ao sucesso das CNN são o facto de permitirem obter representações equivalentes as DNN com parâmetros partilhados. Os parâmetros partilhados nas CNN permitem, ao contrário das fully connected networks, usar completamente o input 2D de imagens e conduzindo a um menor número de parâmetros, que é benéfico dado que facilita o treino e torna a rede mais rápida. Assim a partilha de parâmetros permite reduzir o número de parâmetros, que, para além de facilitar o treino, facilita a generalização e ajuda a prevenir o overfitting;
Para normalizar o input das várias camadas usamos camadas de BatchNormalization.  A batch normalization permite fazer re-centering e re-scaling dos inputs das diferentes camadas permitindo que a rede fique mais estável, previne valores extremos e reduz a necessidade de cada camada de adaptar às mudanças na camada anterior.
Nas dense layers usamos dropout como forma de regularização, para evitar o overfitting. Esta técnica, em cada época, desativa neurónios aleatoriamente, forçando o modelo a aprender as features diferentes e independentes.
Usamos uma parte fully connected após a parte convolutional para facilitar a aprendizagem das features obtidas pelas convolutional layers, de modo a conseguir uma melhor classificação.
Usamos ainda camadas de MaxPooling após convolutional layers de modo a reduzir a dimensão, obtendo menos parâmetros como input da proxima camada. Esta técnica permite "resumir" as informações mais relevantes aprendidas pelas convolutional layers.

Utilizamos a função de ativação "Relu" para as diferentes camadas dados que esta permite evitar problemas como vanishing gradientes, que ocorrem em funções de activação como a sigmoid. Para além disso, a "Relu" também permite um treino mais rápido. Avaliamos com outras variantes da Relu mas a versão normal foi a que produziu melhores resultados, possivelmente porque o nosso modelo não era afetado pelo problema do dying ReLU.
O nosso modelo tem os seguintes componentes:
    1. Uma primeira parte constituída por três blocos com convolutional layers, com 64, 32 e 16 filtros e um kernel (3,3). Estes blocos são constituídos por um stack de duas convolutional layers, com função de ativação Relu e com bath normalization entre elas e terminando com uma camada de MaxPooling.
    2. Após os blocos com convolutional layers fazemos flatten do seu output para que este seja passado adequadamente às Dense layers seguintes.
    3. seguidamente temos 3 dense blocos de 264, 128 e 64 neurónios. Estes blocos são constituídos por uma dense layer com função de ativação Relu, por batch normalization e terminam com uma camada de dropout
    4. Por fim temos a última camada, para output, com 10 neurónios e função de ativação softmax. São 10 neurónios visto que temos 10 classes a que o pokemon na imagem pode pertencer.

O uso da função de activação softmax aplica-se a problemas de classificação em que cada exemplo pode pertencer a uma, e apenas uma das classe, sendo que a função expressão a probabilidade de cada exemplo pertencer a cada classe. Sendo assim podemos concluir a classe prevista pela rede analisando a classe com maior probabilidade. É assim a função de ativação mais adequada para este primeiro problema.

Para a loss function escolhemos categorical_crossentropy dado que é uma loss function que se aplica o problemas de classificação multiclasse, que é o que estamos a avaliar: a qual das 10 classes existentes pertence cada exemplo.

Q2: Discuss and explain how you selected the best model for the multiclass classification problem, showing the relevant plots, comparing the different models you tried and evaluating the results you obtained.
Q2: Discuta e explique como selecionou o melhor modelo para o problema de classificação multi-classe, mostrando os gráficos relevantes, comparando os diferentes modelos que experimentou e avaliando os resultados obtidos.
R2:
Para selecionarmos o melhor modelo fizemos uma série de experiências com diferentes arquiteturas, experimentando modelos com mais e menos convolutional layers, alterando o número de filtros e o tamanho do kernel utilizado, adicionando e removendo layers de Dropout e BatchNormalization e experimentando com diferentes otimizadores.
Para otimizadores o SDG, com diferentes valores para o momentum e learning rate e o Adam, com os valores default. Obtivemos sempre melhores resultados, bem como um treino mais rápido com o otimizador Adam pelo que o escolhemos no nosso modelo final.
Em relação aos parâmetros como o número de cada tipo de camada, ao tamanho do kernel a usar e o número de filtros, realizados diferentes experiências e escolhemos a melhor avaliando o erro de validação obtido com cada modelo.
Experimentamos o modelo com e sem BatchNormalization entre as diferentes camadas mas não obtivemos bons resultados.
Optamos por utilizar camadas de dropout após as dense layers como forma de regularização, evitando o overfitting
Tentamos também uma arquitetura com Residual blocks, que que o input é copiado para o output, mas não obtivemos bons resultados pelo que descartamos este modelo.
Sempre que com modelos diferentes obtínhamos resultados semelhante escolhemos o modelo mais simples, com o menor número de parâmetros. Isto porque modelos mais simples são mais fáceis de treinar e porque modelos complexos podem dificultar a generalização.
A avaliação dos modelos foi feita através do erro de validação e da accuracy medida com os dados de validação. Os modelos que apresentavam piores valores foram descartados.
O modelo selecionado permitiu-nos obter excelentes resultados no teste de treino: Multiclass accuracy: 1.0; Multiclass loss: 0.000170357248862274.
Na imagem images/multiclass-accuracy-best-model.png podemos observar a evolução durante o treino da accuracy de treino e validação, e no ficheiro images/multiclass-loss-best-model.png a evolução da loss, para o modelo selecionado.


Q3: For the multilabel classification problem, explain how you adpated your previous model, what experiments you did to optimize the architecture and discuss your results. Do not forget to explain your choice of activation and loss functions and why this model differs from the previous one.
Q3: Para o problema de classificação com múltiplas etiquetas, explique como adaptou o modelo anterior, que experiências fez para optimizar a arquitectura e discuta os resultados. Não se esqueça de explicar a escolha de funções de activação e custo e porque é que este modelo difere do anterior.
R3:
Dada a semelhança do problema de classificação com múltiplas etiquetas com o problema anterior decidimos manter o mesmo modelo que para o problema anterior, dado que obteu excelentes resultados.
Apesar das semelhanças entre od dois problemas foram necessárias algumas alterações para garantir a adequação do modelo ao novo problema:
    1. Primeiro foi alterada a função de ativação da última dense layer, a camada de output, para sigmoid. A função softmax já não se adequa a este problema dado que a soma das probabilidades de pertencer às diferentes classes é 1, adequando-se a problemas em que os exemplos pertencem apenas a uma classe. Já a função sigmoid pode ser aplicada quando o exemplo pode pertencer a mais que uma classe, dando-nos a probabilidade de cada pokemon pertencer a cada classe.
    2. A segunda alteração foi a loss function para binary_crossentropy, por motivos semelhantes aos anteriores: dado que o pokemon pode pertencer a mais que uma classe queremos que a loss seja calculada para cada classe individualmente.
    3. Finalmente, para avaliar a accuracy escolhemos binary_accuracy em detrimento da categorical_accuracy, pelos mesmos motivos apresentados anteriormente.
Tentamos duas abordagens: primeiro tentamos carregar na rede os pesos previamente obtidos (pesos/multiclass-best_model.h5) e obtivemos os seguintes resultados:
    1. Nos dados destinados ao treino: Multilabel accuracy: 0.7336248159408569; Multilabel loss: 0.5656331181526184
    2. Nos dados reservados para teste: Multilabel accuracy: 0.7408000230789185; Multilabel loss: 0.5622454881668091
Dado que os resultados não foram tão bons como os demonstrados no problema anterior decidimos treinar o modelo e obtivemos os seguintes resultados no conjunto de teste: Multilabel accuracy: 1.0; Multilabel loss: 0.0005157431005500257
Na imagem images/multilabel_best_model_accuracy.png podemos observar a evolução da accuracy no treino e validação do problema de multilabel e na imagem images/multilabel_best_model_loss.png podemos observar a evolução da loss function.


Q4: Explain the architecture of your best model for the semantic segmentation problem, including a description and justification of the output activation and loss functions. Also justify your choice of layers and activation functions for the hidden layers.
Q4: Explique a arquitectura do seu melhor modelo para o problema de segmentação semântica, incluindo uma descrição e justificação das funções de activação à saída da rede e função de custo. Justifique também a sua escolha de camadas e de funções de activação para as camadas escondidas.
R4:
Escolhemos implementar uma rede com convolutional layers devido às propriedades que mencionamos anteriormente, nomeadamente permitir redes com um menor número de parâmetros.Usamos batch normalization pelo mesmo motivo.
Para o problema de segmentação semântica escolhemos um modelo que aplica uma adaptação muito simples de uma arquitetura u-net:
    1. Primeiro temos uma bloco de convolutional layers igual ao blocos dos problemas anteriores (duas convolutional layers com Batch Normalization e uma camada final de Max polling) com um kernel de (2,2) e 16 filtros. Este corresponde ao nível um.
    2. Temos uma camada correspondendo à "base do U" com um bloco de convolutional layers com um kernel de (2,2) e 32 filtros.
    3. Começamos agora a "subida do U" e temos um bloco de UpSampling. Este bloco tem uma camada de upsampling com size=(2, 2), interpolation="nearest", depois concatena o resultado nessa camada com o resultado da camada do mesmo nível do bloco convolutional, sem o MaxPooling. Como só temos um nível a concatenação deste upsampling é com o resultado do bloco de convolutional layers do nível 1, descrito no ponto 1.
    4. Finalmente temos a preparação do output com uma última convolutional layer com 1 filtro e um kernel de (2,2) com função de activação sigmoid. A função de sigmoid permite construir a máscara de segmentação através de uma classificação pixel a pixel.

    A função de activação sigmoid foi escolhida para a camada de output porque é a função de ativação standard neste tipo de problemas.
    Como loss function escolhemos binary_crossentropy dado que estamos a classificar cada pixel da imagem individualmente, tornando-se a loss function mais apropriada.
    Nas camadas escondidas foi utilizada a função de ativação "Relu" pelos mesmos motivos que anteriormente explicados, especialmente para evitar o fenómeno dos vanishing gradients.
    As skip connections na arquitetura u-net permitem passar às últimas camadas informações adicionais que lhes permitem construir uma melhor máscara, dado que fornece um fluxo adicional das camadas anteriores sem degradação. Estas conexões permitem a rede aprender uma melhor representação.


Q5: Discuss and explain how you selected the best model for the semantic segmentation problem, showing the relevant plots, comparing the different models you tried and evaluating the results you obtained. Use the auxiliary functions provided to show the correspondence between your predicted segmentation masks and the masks provided in the test set.
Q5: Discuta e explique como seleccionou o melhor modelo para o problema de segmentação semântica, mostrando os gráficos relevantes, comparando os diferentes modelos que experimentou e avaliando os resultados obtidos. Use as funções auxiliares fornecidas para mostrar a correspondência entre as máscaras de segmentação previstas e as máscaras no conjunto de teste.
R5:
Experimentamos dois tipos de arquiteturas: Fully Convolutional Network e U-net. Observamos que obtínhamos melhores resultados com arquiteturas do tipo U-net pelo que foi o que escolhemos. Podemos ver a diferenças de performance nas imagens: images/segmentation_FCN_vs_u-net_accuracy.png e
 images/segmentation_FCN_vs_u-net_loss.png. Implementamos uma arquitetura muito simples baseada na U-net.
Avaliamos a performance dos diversos modelos avaliando a accuracy e a loss no conjunto de validação e selecionando os com melhores valores.x De entre modelos com performances semelhantes escolhemos sempre o modelo mais simples, com o menor número de parâmetros para treinar. Sendo assim acabados com o modelo muito simples descrito anteriormente.
Nas figuras images/segmentation_best_model_accuracy.png e images/segmentation_best_model_loss.png podemos ver a performance do nosso modelo.
Nas figuras images/segmentation_test_compare.png e images/segmentation_test_overlay.png podemos ter uma noção mais intuitiva das máscaras criadas pelo nosso modelo, comparativamente às máscaras esperadas e às imagens dadas.
A accuracy e a loss obtidas pelo nosso modelo neste problema foram:
Segmentation accuracy: 0.9989907145500183; Segmentation loss: 0.0029769756365567446


Q6: (Optional) Discuss the impact on training and overfitting for the two classification problems when using available networks pretrained on ImageNet (e.g. EfficientNetB0, MobileNetV2 or others). Explain how you used these networks and discuss the effect they had relative to your models.
Q6: (Opcional) Discuta o impacto no treino e sobreajustamento nos dois problemas de classificação se usar redes pré-treinadas no dataset ImageNet (e.g. EfficientNetB0, MobileNetV2 or others). Explique como usou estas redes e discuta o efeito que tiveram nos seus modelos.
R6:
//TODO Reler e ver se concordas com o overfitting em todas as situações do multi-label
Para esta parte do trabalho começamos por nos focar no problema de classificação de multi-classe e posteriormente para trabalhamos no problema de classificação multi-label.
Com isto em mente, construímos uma rede em que incluímos a rede MobileNetV2 em substituição das Convolutional Layers e completámos a mesma construindo as nossas Dense Layers. Utilizamos ainda as mesmas funções de ativação e de loss pelos motivos explicados anteriormente.
Pudemos assim tirar as seguintes conclusões:
    1. Começamos com 3 Dense layers como usamos anteriormente (256,128,64, com dropout como regularização de forma a evitar overfitting) mas obtivemos um modelo em underfitting. (imagens: images/mobileNet_multiclass_dropout_accuracy.png images/mobileNet_multiclass_dropout_loss.png)
    2. Após alterar o número de camadas e o tamanho das mesmas decidimos retirar o dropout onde obtivemos resultados em overfitting. (imagens: images/mobileNet_multiclass_accuracy.png images/mobileNet_multiclass_loss.png)
    3. Por último e a fim de resolver este problema treinamos o modelo com outras formas de regularização, L1, L2 e L1L2 mas obtivemos resultados ainda piores pelo que nos vimos incapazes de encontrar algum equilibrio que tivesse resultados aceitáveis.

Com base nestas observações decidimos que esta rede, MobileNetV2, foi treinada com o objetivo de identificar padrões em imagens muito diferentes das nossas, e assim, mostrou-se incapaz de se adaptar ao contexto do nosso problema.

No problema de classificação multi-label tomamos uma abordagem similar.
Com uma rede semelhante à anterior obtivemos resultados overfitting obtivemos quer quando não utilizamos dropout, por onde começamos, quer quando o utilizamos.
(imagens: images/mobileNet_multilabel_dropout_Accuracy.png images/mobileNet_multilabel_dropout_loss.png images/mobileNet_multilabel_Accuracy.png images/mobileNet_multilabel_Loss.png)
Pelo que este problema, à semelhança do anterior apresenta resultados inferiores aos "originais nossos". No entanto, com uma Accuracy de quase 88%, e uma Loss de 0.33 (aquando parado antes de entrar em overfitting, 20 epochs) este modelo é bastante utilizável dependendo do rigor necessário para a aplicação prática dos resultados.

    
